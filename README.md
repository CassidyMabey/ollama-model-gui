# ollama-model-gui
This project is for my weeks work experience placement where i have explored about why Elucidat could move to a locally housed LLM for all of their AI needs. 
I have experimented with hosting LLM's locally with Ollama and have created a link between the backend(ish) of where the LLM's are hosted and the frontend(ish) of where the website is visable and can be viewed and used.
