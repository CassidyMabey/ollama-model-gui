# ollama-model-gui
This project is for my weeks work experience placement where i have explored about why Elucidat could move to a locally housed LLM for all of their AI needs. <br><br>
I have experimented with hosting LLM's locally with Ollama and have created a link between the backend(ish) of where the LLM's are hosted and the frontend(ish) of where the website is visable and can be viewed and used. <br><br>

## Requirements
To install this, i have provided a requirements.txt which contains all of the pip modules which you will need to run this. <br>
**On Windows** <br>
```bash
pip install -r requirements.txt
```

**On Mac / Linux** 
<br>
```bash
pip3 install -r requirements.txt
```
<br>


